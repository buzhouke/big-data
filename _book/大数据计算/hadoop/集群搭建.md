## 安装jdk

```
yum install java-1.8.0-openjdk  -y
yum install java-1.8.0-openjdk-devel  -y
```

进入相应的文件夹`/usr/lib/jvm`：

```shell
[root@VM-16-2-centos /]# cd /usr/lib
[root@VM-16-2-centos lib]# ls
binfmt.d    games       jvm          modules           sse2
cpp         gcc         jvm-commmon  modules-load.d    sysctl.d
crda        grub        jvm-exports  NetworkManager    systemd
debug       java        jvm-private  polkit-1          tmpfiles.d
dkms        java-1.5.0  kbd          python2.7         tuned
dracut      java-1.6.0  kdump        python3.6         udev
firewalld   java-1.7.0  kernel       rpm               yum-plugins
firmware    java-1.8.0  locale       sendmail
fontconfig  java-ext    modprobe.d   sendmail.postfix
[root@VM-16-2-centos lib]# cd jvm
[root@VM-16-2-centos jvm]# ls
java
java-1.8.0
java-1.8.0-openjdk
java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64 #复制这个
java-openjdk
jre
jre-1.8.0
jre-1.8.0-openjdk
jre-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64
jre-openjdk
```

配置环境变量，编辑文件 `/etc/profile` ，在最后加上：

```shell
#Java
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64
export CALSSPATH=$JAVA_HOME/lib/*.*
export PATH=$PATH:$JAVA_HOME/bin
```

然后查看是否配置成功：

```shell
[root@VM-16-2-centos jvm]# vim /etc/profile
[root@VM-16-2-centos jvm]# source /etc/profile
[root@VM-16-2-centos jvm]# $JAVA_HOME
-bash: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64: Is a directory
[root@VM-16-2-centos jvm]# java --version
Unrecognized option: --version
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
[root@VM-16-2-centos jvm]# java -version
openjdk version "1.8.0_282"
OpenJDK Runtime Environment (build 1.8.0_282-b08)
OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)
```



## 修改 hostname 及 host 文件

分别在两台机器上执行

```
1.15.114.46 hadoop1-master
121.4.94.30 hadoop2-hui
118.89.133.113 hadoop3-slave
```

修改两台机器的 `/etc/hosts` (host 要带 s)文件，添加以下内容

```
[hadoop@VM_0_14_centos root]$ sudo hostname hadoop3-slave
[hadoop@VM_0_14_centos root]$ sudo vim /etc/hosts
[sudo] password for hadoop:
[hadoop@VM_0_14_centos root]$ ping hadoop1-master
PING hadoop1-master (1.15.114.46) 56(84) bytes of data.
64 bytes from hadoop1-master (1.15.114.46): icmp_seq=1 ttl=57 time=3.87 ms
64 bytes from hadoop1-master (1.15.114.46): icmp_seq=2 ttl=57 time=3.61 ms

```

确保各个服务器都能ping得通对方。

配置SSH免密登陆：

hadoop1-master：

```
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDOflo2pl5Ct/yWQwXg1L5h4y0WjU3NlUC1m44IOVuHJwBhQOMVUbsRY5iwwyz9TrQYKem+MGWn75wjG3G8ikTjlVxSgWDMQ2BfBSz4hx3oQfDf+/BUO6TaPizu14EoYuan4N9qhFXt898IsadNw/aaV5GSQWYqW7ihxO8OCy+16ivGdSuht7pt/UGC7k7QYLv+cdMGZ5ebf3Ql+Wl1yTx1Y+fl3DkxDKpl+7xpYhEKOUAJ/Uciws1xm5uqh6V7KbLJlO3UTSTJJIbk6C190KQR381OmS8UhSuFzgBkFdtBRptthkGVDcLId4sKANgMY4+/FFf/YG0p7iEUTEvvxoGd hadoop@hadoop1-master
```

hadoop2-hui:

```
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCfhV4GTPje2Z6V/0gls6U9KnrIvpJTzd6uP9Y2FqDzzOw2MBWqdWUwL/iix7SxEkO2R5BBwA914n9V6aoy0YUjNyesE/jar3iMCZw33XEKZuXNGLZxTNWpZzAIg/+5yCFL/AQCcSF0aC57B/NeNjGv37bpUInBowWctGVd8LztLtJOYUwvoRXAaKJjc5BSHXFDL1eVokN3K5idrOzIRK18OPqD11Z6Bi2N3XuIO6NuasjLmgJWDh8xijnVLWqGLQy7Xa1KaD+QLaa5f+I+VjUjxtiiwmFCoEzHWaiGSEowqC14n1C3XKPQ+j8fGuqfPGfHY7rTWoXOwmObDnKmGMkF hadoop@hadoop2-hui
```

hadoop3-slave:

```
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDA362NeR7z12bLn4C6hWalElgpZuRdBa8Mfh+amGDFM+dahyDYwhQa47DWj3DtNlVZuJT8plS5EK2CwGmT0E3oOoZ/u6uMVjjMIIFdjMMqw50so79+aWE10csHbJppF3KIIXLYbdCm3cfP1zy0dg2I6qK24tLZD63Qbq9cKHifhLGpLcQJr8/7czAmUAM7A/gEXchUKxnM3RCafjzfG+4pEIz5xI76zk+bOcSZ/RRDOGNx22IlCx4ccmZMGP/TQDevGuutUaHt3qQc+StTbJmMMDYOhAjVKiXExmw+fimWJNwyCX7o+nPpHSVyORuwGPbm1VclWmCThvFHsbpiHmjJ root@hadoop3-slave
```



```
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDOflo2pl5Ct/yWQwXg1L5h4y0WjU3NlUC1m44IOVuHJwBhQOMVUbsRY5iwwyz9TrQYKem+MGWn75wjG3G8ikTjlVxSgWDMQ2BfBSz4hx3oQfDf+/BUO6TaPizu14EoYuan4N9qhFXt898IsadNw/aaV5GSQWYqW7ihxO8OCy+16ivGdSuht7pt/UGC7k7QYLv+cdMGZ5ebf3Ql+Wl1yTx1Y+fl3DkxDKpl+7xpYhEKOUAJ/Uciws1xm5uqh6V7KbLJlO3UTSTJJIbk6C190KQR381OmS8UhSuFzgBkFdtBRptthkGVDcLId4sKANgMY4+/FFf/YG0p7iEUTEvvxoGd hadoop@hadoop1-master

ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCfhV4GTPje2Z6V/0gls6U9KnrIvpJTzd6uP9Y2FqDzzOw2MBWqdWUwL/iix7SxEkO2R5BBwA914n9V6aoy0YUjNyesE/jar3iMCZw33XEKZuXNGLZxTNWpZzAIg/+5yCFL/AQCcSF0aC57B/NeNjGv37bpUInBowWctGVd8LztLtJOYUwvoRXAaKJjc5BSHXFDL1eVokN3K5idrOzIRK18OPqD11Z6Bi2N3XuIO6NuasjLmgJWDh8xijnVLWqGLQy7Xa1KaD+QLaa5f+I+VjUjxtiiwmFCoEzHWaiGSEowqC14n1C3XKPQ+j8fGuqfPGfHY7rTWoXOwmObDnKmGMkF hadoop@hadoop2-hui

ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDA362NeR7z12bLn4C6hWalElgpZuRdBa8Mfh+amGDFM+dahyDYwhQa47DWj3DtNlVZuJT8plS5EK2CwGmT0E3oOoZ/u6uMVjjMIIFdjMMqw50so79+aWE10csHbJppF3KIIXLYbdCm3cfP1zy0dg2I6qK24tLZD63Qbq9cKHifhLGpLcQJr8/7czAmUAM7A/gEXchUKxnM3RCafjzfG+4pEIz5xI76zk+bOcSZ/RRDOGNx22IlCx4ccmZMGP/TQDevGuutUaHt3qQc+StTbJmMMDYOhAjVKiXExmw+fimWJNwyCX7o+nPpHSVyORuwGPbm1VclWmCThvFHsbpiHmjJ root@hadoop3-slave
```



在 `/data` 目录下新建几个目录

```shell
sudo mkdir  hadoop
sudo mkdir  hadoop/tmp
sudo mkdir  hadoop/var
sudo mkdir  hadoop/dfs
sudo mkdir  hadoop/dfs/name
sudo mkdir  hadoop/dfs/data
```



## 修改 etc/hadoop 中的一系列配置文件

进入目录 `/usr/local/hadoop-2.8.5/etc/hadoop`

修改 `core-site.xml` 在 `<configuration>` 节点内加入配置

```
<configuration>
   <property>

        <name>hadoop.tmp.dir</name>

        <value>/data/hadoop/tmp</value>

        <description>Abase for other temporary directories.</description>

   </property>

   <property>

        <name>fs.default.name</name>

        <value>hdfs://hadoop1-master:9000</value>

   </property>
</configuration>
```

修改 `hadoop-env.sh` 将 `${JAVA_HOME}` 修改为自己的 jdk 路径

```
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64

/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64


```

修改 `hdfs-site.xml` 加入配置

```
<property>

   <name>dfs.name.dir</name>

   <value>/data/hadoop/dfs/name</value>

   <description>Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.</description>

</property>

<property>

   <name>dfs.data.dir</name>

   <value>/data/hadoop/dfs/data</value>

   <description>Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.</description>

</property>

<property>

   <name>dfs.replication</name>

   <value>2</value>

</property>

<property>

      <name>dfs.permissions</name>

      <value>false</value>

      <description>need not permissions</description>

</property>
```

新建并且修改 `mapred-site.xml`

复制目录中的 template 文件并重命名

```
cp mapred-site.xml.template mapred-site.xml
```

加入配置

```
<property>

   <name>mapred.job.tracker</name>

   <value>hadoop1-master:49001</value>

</property>

<property>

      <name>mapred.local.dir</name>

       <value>/data/hadoop/var</value>

</property>


<property>

       <name>mapreduce.framework.name</name>

       <value>yarn</value>

</property>
```

修改 `slaves` 文件，将其中的 localhost 删除并添加自己的 datanode

```
hadoop2-hui
hadoop3-slave
```

修改 `yarn-site.xml` 文件，加入配置

```
<property>

        <name>yarn.resourcemanager.hostname</name>

        <value>hadoop1-master</value>

   </property>

   <property>

        <name>yarn.nodemanager.aux-services</name>

        <value>mapreduce_shuffle</value>

   </property>
```

在另一台机器上重复上述操作，文件可以直接复制，涉及六个文件，两台服务器上保持完全一致

```
core-site.xml, mapred-site.xml, yarn-site.xml, slaves, hadoop-env.sh，hdfs-site.xml
```

其中涉及到 jdk 路径需要修改为 `java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.aarch64`

进展：

- 发现各jdk路径不统一，发现Hadoop集群默认账号为hadoop

  解决思路：

  ​	1. 继续改进现有的：

  ​			先忽略jdk路径问题，

  ​			然后找官网查询第二种如何更改

  ​	2. 尝试docker容器化部署

- 发现新购买的服务器无法通过IP地址访问，关闭防火墙仍然不起作用

## 逐渐跑题

简单整理下思路：

为什么搭建Hadoop集群？学习的HBase依赖Hadoop生态且大多数大数据组件同理

实际需要：Flink集群，两种方案：yarn，k8s

Flink集群最基础的搭建方案：https://www.cnblogs.com/smartloli/p/5757498.html

Flink集群基于k8s的搭建方案：https://blog.csdn.net/shirukai/article/details/109452700

Flink集群基于yarn的搭建方案：https://blog.csdn.net/weixin_45783164/article/details/105840902



yysy，看起来真简单

目前看来所需要的技术：

HBase，Kfaka（附带学习Zookeeper），Flink

所依赖的基础：

Linux运维技能，Shell脚本语言编写，Scala语言，~~Java基础，maven环境~~

2/8-2/14所需要完成：

- SpringBoot如何调用深度学习算法模型
- 集群搭建（服务器相应环境准备）
- 跟进A09其他组员任务, 思考如何进行项目管理

k8s搭建Flink框架：

[Flink on K8s 技术演进：如何原生地在 Kubernetes 上运行 Flink？](https://www.infoq.cn/article/lEEkGkETVKyTe33RKjH0)



## Reference

https://segmentfault.com/a/1190000023041375

https://blog.csdn.net/gakki_smile/article/details/77198146

https://hadoop.apache.org/docs/r2.8.5/hadoop-project-dist/hadoop-common/ClusterSetup.html

# Hadoop docker

```shell
 sudo docker ps
[sudo] password for wangww:
CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS                         NAMES
cc3e904f2e70        selenium/standalone-chrome   "/opt/bin/entry_poin…"   2 days    ago          Up 2 days           0.0.0.0:4444->4444/tcp        modest_tereshkov   a
6c3c24d05bbf        englishpal                   "/entrypoint.sh /sta…"   2 days    ago          Up 2 days           443/tcp, 0.0.0.0:91->80/tcp   focused_satoshi

```

emm，先安装Flink集群，后安装Hadoop集群，探索Flink on yarn模式。



发现灰灰的服务器，是专门弄了一个sudo用户组，用`cat /etc/group`查看用户组，用` sudo usermod -aG sudo hadoop`将hadoop用户加入用户组才获得管理员权限，学到了！



```
scp -r /usr/local/flink-1.12.1 hadoop@hadoop1-master:/usr/local/
scp -r /usr/local/flink-1.12.1 hadoop@hadoop3-slave:/usr/local/
```



```
iptables -I INPUT -p tcp --dport 50070 -j ACCEPT
```



# Hadoop02

### 配置集群/分布式环境

集群/分布式模式需要修改 /usr/local/hadoop/etc/hadoop 中的5个配置文件，更多设置项可点击查看官方说明，这里仅设置了正常启动所必须的设置项： slaves、[core-site.xml](http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/core-default.xml)、[hdfs-site.xml](http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)、[mapred-site.xml](http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)、[yarn-site.xml](http://hadoop.apache.org/docs/r2.6.0/hadoop-yarn/hadoop-yarn-common/yarn-default.xml) 。

1, 文件 **slaves**，将作为 DataNode 的主机名写入该文件，每行一个，默认为 localhost，所以在伪分布式配置时，节点即作为 NameNode 也作为 DataNode。分布式配置可以保留 localhost，也可以删掉，让 Master 节点仅作为 NameNode 使用。

此教程让 Master 节点仅作为 NameNode 使用，因此将文件中原来的 localhost 删除，只添加一行内容：Slave1。

![img](https://img-blog.csdnimg.cn/20200227160235853.png)

2、文件 **core-site.xml** 改为下面的配置

```
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop1-master:9000</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>file:/usr/local/hadoop-2.8.5/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
</configuration>
```

3、文件 **hdfs-site.xml**，dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值设为 1

```
<configuration>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoop1-master:50090</value>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/usr/local/hadoop-2.8.5/tmp/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/usr/local/hadoop-2.8.5/tmp/dfs/data</value>
        </property>
</configuration>
```

4、文件 **mapred-site.xml** （先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：

```
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
          <value>yarn</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>hadoop1-master:10020</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>hadoop1-master:19888</value>
        </property>
</configuration>
```

5、文件 **yarn-site.xml**

```
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>hadoop1-master</value>
        </property>
    <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
</configuration>
```

**配置好后，将 Master 上的 /usr/local/hadoop 文件夹复制到各个节点上。**

```
scp -r /usr/local/hadoop-2.8.5 hadoop@hadoop2-hui:/usr/local/
scp -r /usr/local/hadoop-2.8.5 hadoop@hadoop3-slave:/usr/local/ 
```

因为之前有跑过伪分布式模式，建议在切换到集群模式前先删除之前的临时文件。

在 Master 节点上执行如下操作

```
cd /usr/local    



sudo rm -r ./hadoop/tmp                            # 删除 Hadoop 临时文件



sudo rm -r ./hadoop/logs/*                         # 删除日志文件



tar -zcf hadoop.tar.gz hadoop                      # 先压缩再复制



cd ~



scp ./hadoop.tar.gz Slave1:/home/hadoop
```

在 Slave1 节点上执行（可不用命令解压，直接在文件系统中提取，解压或提取时间较长，耐心等待）

```
sudo rm -r /usr/local/hadoop                # 删掉旧的（如果存在）



tar -zxf hadoop.tar.gz -C /usr/local



sudo chown -R hadoop /usr/local/hadoop
```

> PS：压缩和解压过程可能会出现重目录现象（解压后hadoop文件夹里面套了一个hadoop文件夹，而第二个文件夹里面才是我们要用到的hadoop环境），此过程自己查看不在赘述

同样，如果有其他 Slave 节点，也要执行将 hadoop.tar.gz 传输到 Slave 节点、在 Slave 节点解压文件的操作。

首次启动需要先在 Master 节点执行 NameNode 的格式化

```
hdfs namenode -format       # 首次运行需要执行初始化，之后不需要
```

接着可以启动 hadoop 了，在 Master 节点上进行

```
start-dfs.sh



start-yarn.sh



mr-jobhistory-daemon.sh start historyserver
```

通过命令 `jps` 可以查看各个节点所启动的进程。正确的话，在 Master 节点上可以看到 NameNode、ResourceManager、SecondrryNameNode、JobHistoryServer 进程

![img](https://img-blog.csdnimg.cn/20200227162228589.png)

在 Slave 节点可以看到 DataNode 和 NodeManager 进程

![img](https://img-blog.csdnimg.cn/20200227162316976.png)

缺少任一进程都表示出错。另外还需要在 Master 节点上通过命令 `hdfs dfsadmin -report` 查看 DataNode 是否正常启动，如果 Live datanodes 不为 0 ，则说明集群启动成功。例如我这边一共有 1 个 Datanodes：

```
hdfs dfsadmin -report
```

![img](https://img-blog.csdnimg.cn/20200227162504540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI2MTY0NjA5,size_16,color_FFFFFF,t_70)

也可以通过 Web 页面看到查看 DataNode 和 NameNode 的状态http://master:50070/

> ### 执行分布式实例

执行分布式实例过程与伪分布式模式一样，首先创建 HDFS 上的用户目录

```
hdfs dfs -mkdir -p /user/hadoop
```

将 /usr/local/hadoop/etc/hadoop 中的配置文件作为输入文件复制到分布式文件系统中

```
hdfs dfs -mkdir input



hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input
```

通过查看 DataNode 的状态（占用大小有改变），输入文件确实复制到了 DataNode 中

![img](https://img-blog.csdnimg.cn/20200227163156636.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI2MTY0NjA5,size_16,color_FFFFFF,t_70)

关闭 Hadoop 集群也是在 Master 节点上执行的

```
stop-yarn.sh



stop-dfs.sh



mr-jobhistory-daemon.sh stop historyserver
```



https://blog.csdn.net/qq_26164609/article/details/104535625



```shell
./start-all.sh
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
Starting namenodes on [hadoop1-master]
hadoop1-master: starting namenode, logging to /usr/local/hadoop-2.8.5/logs/hadoop-hadoop-namenode-hadoop1-master.out
hadoop3-slave: /home/hadoop/.bashrc: line 21: hadoop: command not found
hadoop3-slave: starting datanode, logging to /usr/local/hadoop-2.8.5/logs/hadoop-hadoop-datanode-hadoop3-slave.out
hadoop3-slave: nice: /usr/local/hadoop/bin/hdfs: No such file or directory
Starting secondary namenodes [hadoop1-master]
hadoop1-master: starting secondarynamenode, logging to /usr/local/hadoop-2.8.5/logs/hadoop-hadoop-secondarynamenode-hadoop1-master.out
starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop-2.8.5/logs/yarn-hadoop-resourcemanager-hadoop1-master.out
hadoop3-slave: /home/hadoop/.bashrc: line 21: hadoop: command not found
hadoop3-slave: starting nodemanager, logging to /usr/local/hadoop-2.8.5/logs/yarn-hadoop-nodemanager-hadoop3-slave.out
hadoop3-slave: Error: Could not find or load main class org.apache.hadoop.yarn.server.nodemanager.NodeManager

```



```
PATH=$PATH:$HOME/bin:/usr/local/hadoop-2.8.5/bin
```



```
172.17.16.2
```



![image-20210215203108385](https://buhzou-1300695412.cos.ap-nanjing.myqcloud.com/image-20210215203108385.png)

8088端口无法访问：

```
[hadoop@hadoop1-master hadoop]$ vim yarn-site.xml
[hadoop@hadoop1-master hadoop]$ netstat -anp |grep 50070
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:50070           0.0.0.0:*               LISTEN      13488/java
[hadoop@hadoop1-master hadoop]$ netstat -anp |grep 8088
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp6       0      0 172.17.16.2:8088        :::*                    LISTEN      13955/java

```



![image-20210215222143607](https://buhzou-1300695412.cos.ap-nanjing.myqcloud.com/image-20210215222143607.png)